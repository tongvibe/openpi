{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "import jax\n",
    "\n",
    "from openpi.models import model as _model\n",
    "from openpi.policies import droid_policy\n",
    "from openpi.policies import policy_config as _policy_config\n",
    "from openpi.shared import download\n",
    "from openpi.training import config as _config\n",
    "from openpi.training import data_loader as _data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy inference\n",
    "\n",
    "The following example shows how to create a policy from a checkpoint and run inference on a dummy example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint downloaded to: /root/.cache/openpi/openpi-assets/checkpoints/pi0_fast_droid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some kwargs in processor config are unused and will not have any effect: min_token, action_dim, time_horizon, scale, vocab_size. \n",
      "Some kwargs in processor config are unused and will not have any effect: min_token, action_dim, time_horizon, scale, vocab_size. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions shape: (10, 8)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = _config.get_config(\"pi0_fast_droid\")\n",
    "checkpoint_dir = download.maybe_download(\"s3://openpi-assets/checkpoints/pi0_fast_droid\")\n",
    "print(\"Checkpoint downloaded to:\", checkpoint_dir)\n",
    "\n",
    "# Create a trained policy.\n",
    "policy = _policy_config.create_trained_policy(config, checkpoint_dir)\n",
    "\n",
    "# Run inference on a dummy example. This example corresponds to observations produced by the DROID runtime.\n",
    "example = droid_policy.make_droid_example()\n",
    "result = policy.infer(example)\n",
    "\n",
    "# Delete the policy to free up memory.\n",
    "del policy\n",
    "\n",
    "print(\"Actions shape:\", result[\"actions\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with a live model\n",
    "\n",
    "\n",
    "The following example shows how to create a live model from a checkpoint and compute training loss. First, we are going to demonstrate how to do it with fake data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: (1, 50)\n",
      "[[9.128082  8.807123  8.616392  8.909349  8.866441  8.331093  8.623332\n",
      "  8.269854  8.772354  8.809507  7.9495163 8.170952  8.852371  8.389737\n",
      "  8.961611  8.289936  8.176186  7.990792  8.255247  8.0972595 8.1045\n",
      "  8.130877  8.136462  7.9967995 7.969477  7.990366  8.517185  8.204456\n",
      "  7.3827057 8.35801   8.100222  7.6314535 7.79031   8.697946  8.020273\n",
      "  7.918974  8.298997  7.7337446 8.041628  8.003708  7.8390265 8.053684\n",
      "  7.9783554 8.584342  8.673449  8.223232  8.627295  8.290242  7.978609\n",
      "  9.183986 ]]\n"
     ]
    }
   ],
   "source": [
    "config = _config.get_config(\"pi0_aloha_sim\")\n",
    "\n",
    "checkpoint_dir = download.maybe_download(\"s3://openpi-assets/checkpoints/pi0_aloha_sim\")\n",
    "# print(\"Checkpoint downloaded to:\", checkpoint_dir)\n",
    "\n",
    "key = jax.random.key(0)\n",
    "\n",
    "# Create a model from the checkpoint.\n",
    "model = config.model.load(_model.restore_params(checkpoint_dir / \"params\"))\n",
    "\n",
    "# We can create fake observations and actions to test the model.\n",
    "obs, act = config.model.fake_obs(), config.model.fake_act()\n",
    "\n",
    "# Sample actions from the model.\n",
    "loss = model.compute_loss(key, obs, act)\n",
    "print(\"Loss shape:\", loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to create a data loader and use a real batch of training data to compute the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a2694b31f2044b7a0bdbf942152ea67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a37c14d5d6a4e4fa907efb3baa21a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e91769eb84495792afc06046833678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 106 files:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cda3cd24454482db59aac34d5d6d9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss shape: (2, 50)\n",
      "[[0.16305491 0.16936925 0.17258719 0.17509273 0.16549909 0.17259395\n",
      "  0.15390736 0.15149112 0.15859419 0.15400508 0.14487183 0.14287466\n",
      "  0.14395398 0.14725338 0.15673023 0.15144402 0.15445954 0.1614206\n",
      "  0.16689792 0.16941643 0.17953211 0.19078353 0.1857508  0.20530383\n",
      "  0.21838504 0.22986919 0.24887243 0.27364165 0.27926794 0.30435103\n",
      "  0.3344978  0.36285368 0.36504626 0.38305753 0.41475707 0.45635572\n",
      "  0.48581845 0.52128434 0.54498327 0.6158477  0.6252788  0.6834529\n",
      "  0.68625534 0.7348676  0.79612076 0.79155254 0.81713223 0.8567008\n",
      "  0.84930444 0.8213333 ]\n",
      " [0.10275582 0.10470946 0.1043144  0.11545829 0.11299162 0.11235681\n",
      "  0.11203268 0.10946272 0.09947442 0.1066063  0.10297152 0.09772962\n",
      "  0.10122444 0.09798466 0.10198066 0.09790149 0.10567708 0.111296\n",
      "  0.10884148 0.12303942 0.12316433 0.13894933 0.13322476 0.14326176\n",
      "  0.1546779  0.17019024 0.17846107 0.1934481  0.2125881  0.23278277\n",
      "  0.2537644  0.27986088 0.32630974 0.34754717 0.3839236  0.41825342\n",
      "  0.46552694 0.49692658 0.52267706 0.5751507  0.5626175  0.5790913\n",
      "  0.5999124  0.5899081  0.6387882  0.6379852  0.6317915  0.6329504\n",
      "  0.6275377  0.6152458 ]]\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value\n",
    "\n",
    "\n",
    "# Reduce the batch size to reduce memory usage.\n",
    "config = dataclasses.replace(config, batch_size=2)\n",
    "\n",
    "# Load a single batch of data. This is the same data that will be used during training.\n",
    "# NOTE: In order to make this example self-contained, we are skipping the normalization step\n",
    "# since it requires the normalization statistics to be generated using `compute_norm_stats`.\n",
    "loader = _data_loader.create_data_loader(config, num_batches=1, skip_norm_stats=True)\n",
    "obs, act = next(iter(loader))\n",
    "\n",
    "# Sample actions from the model.\n",
    "loss = model.compute_loss(key, obs, act)\n",
    "\n",
    "# Delete the model to free up memory.\n",
    "del model\n",
    "\n",
    "print(\"Loss shape:\", loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenPI Environment",
   "language": "python",
   "name": "openpi-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
